"""
This script was used to analyze the metadata of the subtitles dump provided by OpenSubtitles team.
"""
import csv
import io

DUMP_FILE = './export.txt'  # provided by OpenSubtitles
IDS_FILE = './ids.txt'  # generated by missing_data_finder.py from movies.jsonl data (not pushed to repository because the file is too large)
SKIP_LINES = 1
output = dict()  # MovieImdbID (if we have data for it) -> {IDSubtitleFile, SubDownloadsCnt}
set_of_ids = dict()

# file = open(DUMP_FILE, 'r')
file = io.open(DUMP_FILE, mode='r', encoding='utf-8')
for i in range(SKIP_LINES):
    next(file)

with open(IDS_FILE, 'r') as ids_file:
    for line in ids_file:
        line_split = line.strip().split('-')
        id_num = int(line_split[0])
        id_actual = line_split[1]
        set_of_ids[id_num] = id_actual


reader = csv.DictReader(file, delimiter='\t', quoting=csv.QUOTE_NONE)
for row in reader:
    if row['MovieImdbID'] is not None and row['MovieImdbID'] != '' and len(row['MovieImdbID'].strip().lstrip('0')) > 0:
        id = int(row['MovieImdbID'].strip().lstrip('0'))
        if id in set_of_ids:
            dlCount = int(row['SubDownloadsCnt'])
            if id not in output:
                output[id] = {'subFile': row['IDSubtitleFile'], 'dlCount': dlCount}
            elif dlCount > output[id]['dlCount']:  # it is already in the output. Let's check if the new subfile is more popular
                output[id] = {'subFile': row['IDSubtitleFile'], 'dlCount': dlCount}

with open('clean.csv', 'w', newline='') as csvfile:
    fieldnames = ['idNum', 'idActual', 'subFile', 'dlCount']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    for id in output.keys():
        writer.writerow({'idNum': id, 'idActual': set_of_ids[id], 'subFile': output[id]['subFile'], 'dlCount': output[id]['dlCount']})

print("We now have subtitles for {} movies out of {}".format(len(output.keys()), len(set_of_ids)))





